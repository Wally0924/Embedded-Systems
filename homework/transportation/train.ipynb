{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wally0924/Embedded-Systems/blob/main/homework/transportation/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_a7RBVllTOCd"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud3EbpV5O4QA"
      },
      "source": [
        "## dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b7vyugLmYjYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da927c71-3925-44cb-ccb3-8ecbb4f78fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   894  100   894    0     0    700      0  0:00:01  0:00:01 --:--:--   700\n",
            "100 10.0M  100 10.0M    0     0  3182k      0  0:00:03  0:00:03 --:--:-- 6377k\n",
            "Archive:  ./roboflow.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            " extracting: data.yaml               \n",
            "   creating: test/\n",
            "   creating: test/images/\n",
            " extracting: test/images/youtube-0_jpg.rf.cefdef78147575c7dcdee4eaadf6978e.jpg  \n",
            " extracting: test/images/youtube-102_jpg.rf.360b3b2577d6d98dd4af8917bc431296.jpg  \n",
            " extracting: test/images/youtube-105_jpg.rf.ec6867fa02ded89a6f3d04087d6a05c7.jpg  \n",
            " extracting: test/images/youtube-120_jpg.rf.2452017d460cc54eae29f47dca6132a3.jpg  \n",
            " extracting: test/images/youtube-127_jpg.rf.071414e4c5d73e12c686d20e1281e6f9.jpg  \n",
            " extracting: test/images/youtube-136_jpg.rf.aeb6348170c695d9661ddfb5dd550c95.jpg  \n",
            " extracting: test/images/youtube-150_jpg.rf.2b25c19dad81aca60cf607deab06fd08.jpg  \n",
            " extracting: test/images/youtube-151_jpg.rf.42f1323bd563d0789ffd17e264152faf.jpg  \n",
            " extracting: test/images/youtube-27_jpg.rf.44f1388250c02c34dfbb1b09c0893bef.jpg  \n",
            " extracting: test/images/youtube-33_jpg.rf.310ce83c455234bd610a967bc016ac54.jpg  \n",
            " extracting: test/images/youtube-5_jpg.rf.36fbc69e61666f265324777b6344c8fe.jpg  \n",
            " extracting: test/images/youtube-65_jpg.rf.43881fc384f860a8432cf27a9b43244b.jpg  \n",
            " extracting: test/images/youtube-78_jpg.rf.e4c02f3311c996ef345fea95d8e2f8d6.jpg  \n",
            " extracting: test/images/youtube-8_jpg.rf.2708d204cea1d9395ad32b8cf1e47359.jpg  \n",
            "   creating: test/labels/\n",
            " extracting: test/labels/youtube-0_jpg.rf.cefdef78147575c7dcdee4eaadf6978e.txt  \n",
            " extracting: test/labels/youtube-102_jpg.rf.360b3b2577d6d98dd4af8917bc431296.txt  \n",
            " extracting: test/labels/youtube-105_jpg.rf.ec6867fa02ded89a6f3d04087d6a05c7.txt  \n",
            " extracting: test/labels/youtube-120_jpg.rf.2452017d460cc54eae29f47dca6132a3.txt  \n",
            " extracting: test/labels/youtube-127_jpg.rf.071414e4c5d73e12c686d20e1281e6f9.txt  \n",
            " extracting: test/labels/youtube-136_jpg.rf.aeb6348170c695d9661ddfb5dd550c95.txt  \n",
            " extracting: test/labels/youtube-150_jpg.rf.2b25c19dad81aca60cf607deab06fd08.txt  \n",
            " extracting: test/labels/youtube-151_jpg.rf.42f1323bd563d0789ffd17e264152faf.txt  \n",
            " extracting: test/labels/youtube-27_jpg.rf.44f1388250c02c34dfbb1b09c0893bef.txt  \n",
            " extracting: test/labels/youtube-33_jpg.rf.310ce83c455234bd610a967bc016ac54.txt  \n",
            " extracting: test/labels/youtube-5_jpg.rf.36fbc69e61666f265324777b6344c8fe.txt  \n",
            " extracting: test/labels/youtube-65_jpg.rf.43881fc384f860a8432cf27a9b43244b.txt  \n",
            " extracting: test/labels/youtube-78_jpg.rf.e4c02f3311c996ef345fea95d8e2f8d6.txt  \n",
            " extracting: test/labels/youtube-8_jpg.rf.2708d204cea1d9395ad32b8cf1e47359.txt  \n",
            "   creating: train/\n",
            "   creating: train/images/\n",
            " extracting: train/images/youtube-103_jpg.rf.627cfd0e3db2dcdd327ca303d268ea04.jpg  \n",
            " extracting: train/images/youtube-104_jpg.rf.39ba30657004c67e24207006e92ec7f8.jpg  \n",
            " extracting: train/images/youtube-106_jpg.rf.a654800df370fb72054ea2ab7845322e.jpg  \n",
            " extracting: train/images/youtube-107_jpg.rf.5efb0d75969553739465bbca3613b7e9.jpg  \n",
            " extracting: train/images/youtube-110_jpg.rf.f1bee775c9ac171015a033b08e133e26.jpg  \n",
            " extracting: train/images/youtube-112_jpg.rf.0a555b8105499df88467fde0701c269e.jpg  \n",
            " extracting: train/images/youtube-112_jpg.rf.ff323bb7062ba870544ae89098c03762.jpg  \n",
            " extracting: train/images/youtube-114_jpg.rf.eddddc9d068520a74adc8337b2976fd2.jpg  \n",
            " extracting: train/images/youtube-116_jpg.rf.ab16d6296bd364c408b5a10cc6a26007.jpg  \n",
            " extracting: train/images/youtube-117_jpg.rf.c2792193a6d0885f9eaa66f9d6c321a0.jpg  \n",
            " extracting: train/images/youtube-119_jpg.rf.c17b4c3736fca8743e060035e8427454.jpg  \n",
            " extracting: train/images/youtube-120_jpg.rf.6563b44f4e4bac53dfca94a205b58916.jpg  \n",
            " extracting: train/images/youtube-121_jpg.rf.1c77931b143cc706ad5d570fa75e3bdb.jpg  \n",
            " extracting: train/images/youtube-123_jpg.rf.8f9dda47c14bc19514a4aebaf553d25a.jpg  \n",
            " extracting: train/images/youtube-124_jpg.rf.5984af8dcba0df650f5cdc2bfacff380.jpg  \n",
            " extracting: train/images/youtube-124_jpg.rf.a00081154de49ba85bd73fd1218783d2.jpg  \n",
            " extracting: train/images/youtube-129_jpg.rf.d19ed916f875cc05cdc4c84d41b8fed0.jpg  \n",
            " extracting: train/images/youtube-12_jpg.rf.927c83638feb49b43ad150396f34ea41.jpg  \n",
            " extracting: train/images/youtube-130_jpg.rf.62605d4bbf5a09faa4a15ed05a4976fd.jpg  \n",
            " extracting: train/images/youtube-130_jpg.rf.ab077fb0c3af6703e083c8bf7abf7839.jpg  \n",
            " extracting: train/images/youtube-131_jpg.rf.be3ee201a2d20969c8dd1a1760128532.jpg  \n",
            " extracting: train/images/youtube-133_jpg.rf.e814fda87ead61ff013a4c52722b109c.jpg  \n",
            " extracting: train/images/youtube-137_jpg.rf.4c506ce6496379f43e06b6fbe90c6f26.jpg  \n",
            " extracting: train/images/youtube-137_jpg.rf.f202c0edfaf34a2b742c0c3894ff4944.jpg  \n",
            " extracting: train/images/youtube-138_jpg.rf.16c5b69d46b286d1ff481c46f4351216.jpg  \n",
            " extracting: train/images/youtube-140_jpg.rf.f29ff14ac179b6df877cb62d792b1074.jpg  \n",
            " extracting: train/images/youtube-141_jpg.rf.945ec3bcd999cf5ff428ec1094a1358a.jpg  \n",
            " extracting: train/images/youtube-143_jpg.rf.4ee725bec7561afe53c51ebb78b271e7.jpg  \n",
            " extracting: train/images/youtube-144_jpg.rf.0e79ef9b3d47a5b1a2499b3a9777c169.jpg  \n",
            " extracting: train/images/youtube-145_jpg.rf.1fc25d3a4e06b4983c96cb14468b46de.jpg  \n",
            " extracting: train/images/youtube-148_jpg.rf.7038db39b441a86076ff712c99781a68.jpg  \n",
            " extracting: train/images/youtube-151_jpg.rf.29ef4e86516ebb6afd852ae747aea36c.jpg  \n",
            " extracting: train/images/youtube-15_jpg.rf.dcad7a2c83a517d0debd19066d0def34.jpg  \n",
            " extracting: train/images/youtube-16_jpg.rf.060d4051e07e49d4b7554ab245945e34.jpg  \n",
            " extracting: train/images/youtube-17_jpg.rf.2b55ded179ef004b3edad03b300c879b.jpg  \n",
            " extracting: train/images/youtube-19_jpg.rf.3b30e8eebc05c3cbb735d64417d8d3f6.jpg  \n",
            " extracting: train/images/youtube-20_jpg.rf.1766333b5814ba31875b7b1dd373ccac.jpg  \n",
            " extracting: train/images/youtube-22_jpg.rf.d571de09a603f6cdd78f68f5d0a642b8.jpg  \n",
            " extracting: train/images/youtube-23_jpg.rf.b38fef22f7358d748328e71c1c0b1e35.jpg  \n",
            " extracting: train/images/youtube-24_jpg.rf.8455f8e5879475e057bf951061b475d7.jpg  \n",
            " extracting: train/images/youtube-25_jpg.rf.9c5c68a195871713fbcefeb66ea37718.jpg  \n",
            " extracting: train/images/youtube-26_jpg.rf.c8844b1f3da80f230f692912df8b2d41.jpg  \n",
            " extracting: train/images/youtube-28_jpg.rf.a794dd5de7822088e4372ec1907e0eb0.jpg  \n",
            " extracting: train/images/youtube-2_jpg.rf.560d8a73505f2d2df4f8869048561785.jpg  \n",
            " extracting: train/images/youtube-30_jpg.rf.49fce322aeabae042753410b3b2e1a33.jpg  \n",
            " extracting: train/images/youtube-31_jpg.rf.58eacdb21efb9e8074ca40e87626a594.jpg  \n",
            " extracting: train/images/youtube-35_jpg.rf.ad275f24b66b634ab7b9eb62966855a0.jpg  \n",
            " extracting: train/images/youtube-36_jpg.rf.1d418652cc78dff6deb1ccc6826b986d.jpg  \n",
            " extracting: train/images/youtube-37_jpg.rf.e6e6de59d7bb29512cdc60723d168b2b.jpg  \n",
            " extracting: train/images/youtube-39_jpg.rf.0880a55cd6c93d3b58fdcd3645f3daf2.jpg  \n",
            " extracting: train/images/youtube-40_jpg.rf.9629254ced5e1a8432aa91f682f0c157.jpg  \n",
            " extracting: train/images/youtube-41_jpg.rf.12ac341868ffca0a7d87bf14cec2e87e.jpg  \n",
            " extracting: train/images/youtube-44_jpg.rf.2b3e21f0391e0b3b971e800a4598b636.jpg  \n",
            " extracting: train/images/youtube-45_jpg.rf.1b7d98b0795536133be1c5e62622cf3a.jpg  \n",
            " extracting: train/images/youtube-48_jpg.rf.0df4d49c270df189a0f0ab4586bcd60c.jpg  \n",
            " extracting: train/images/youtube-4_jpg.rf.a7f901486b15ab7f673b1168fbbceb2e.jpg  \n",
            " extracting: train/images/youtube-50_jpg.rf.885e627443de2555682788c7554cf541.jpg  \n",
            " extracting: train/images/youtube-51_jpg.rf.074f47df3bea6217444e0601a9a494bd.jpg  \n",
            " extracting: train/images/youtube-52_jpg.rf.0bcc217e83b3176790bbac6d6797c8df.jpg  \n",
            " extracting: train/images/youtube-53_jpg.rf.d5f294fb0d7d2e5400c545be3ee5eb91.jpg  \n",
            " extracting: train/images/youtube-54_jpg.rf.fc878b8c350a6c9095b1b78c80577037.jpg  \n",
            " extracting: train/images/youtube-55_jpg.rf.050a4cae88e32ff029c75d3607ada0cc.jpg  \n",
            " extracting: train/images/youtube-56_jpg.rf.596c86f72313ea9e0e851db88f78a63a.jpg  \n",
            " extracting: train/images/youtube-58_jpg.rf.ed01d8acead8d4d094ebb2293e5e8fef.jpg  \n",
            " extracting: train/images/youtube-60_jpg.rf.e35de5f03f4f578083cb05ea69fcae5b.jpg  \n",
            " extracting: train/images/youtube-61_jpg.rf.86e5dacdf20a36d2bcb29c04dc646138.jpg  \n",
            " extracting: train/images/youtube-63_jpg.rf.43ebce342c9f30b4260dc8c999326631.jpg  \n",
            " extracting: train/images/youtube-64_jpg.rf.750942f30364efb538b71d40f302bc6f.jpg  \n",
            " extracting: train/images/youtube-66_jpg.rf.9921dba835a67d29911cdbc768225290.jpg  \n",
            " extracting: train/images/youtube-67_jpg.rf.2ff8d927a07c64f84236e35333cc831e.jpg  \n",
            " extracting: train/images/youtube-68_jpg.rf.3f571fd05de86821abda984184cf4766.jpg  \n",
            " extracting: train/images/youtube-69_jpg.rf.722f4cb1ae7216905959766f1da98f25.jpg  \n",
            " extracting: train/images/youtube-6_jpg.rf.b5da2151ad1afc589d46a277ae5b16ee.jpg  \n",
            " extracting: train/images/youtube-70_jpg.rf.1fdedbb7f7e6465413efa8538b9b683b.jpg  \n",
            " extracting: train/images/youtube-71_jpg.rf.0e4099482394b04a0a6d1f5e852e914a.jpg  \n",
            " extracting: train/images/youtube-72_jpg.rf.5239daddc140feccdb1396d5e61f5060.jpg  \n",
            " extracting: train/images/youtube-73_jpg.rf.ceb75929e75f8fdb2570e9db5c611542.jpg  \n",
            " extracting: train/images/youtube-74_jpg.rf.aea85df397b20ab30b83f30357ae16c2.jpg  \n",
            " extracting: train/images/youtube-75_jpg.rf.331f00d798839023b3239d113ba94f76.jpg  \n",
            " extracting: train/images/youtube-76_jpg.rf.f62ffa25fbf19d4c3c7eb6da6a75b126.jpg  \n",
            " extracting: train/images/youtube-77_jpg.rf.04c447c256bd1e721909147fdd884468.jpg  \n",
            " extracting: train/images/youtube-79_jpg.rf.48a637bce8980c9bc79a6399ef53cb41.jpg  \n",
            " extracting: train/images/youtube-80_jpg.rf.b4866119b9e91331d21734edb4907f71.jpg  \n",
            " extracting: train/images/youtube-82_jpg.rf.f34e75c0d9d468a93eb081b3f397bc25.jpg  \n",
            " extracting: train/images/youtube-83_jpg.rf.4ea5ea38948553093e9cfb59474c8c02.jpg  \n",
            " extracting: train/images/youtube-86_jpg.rf.f279f20a3e476e01e4636b948b17ecb2.jpg  \n",
            " extracting: train/images/youtube-88_jpg.rf.d75f37d9b7d64b838202eff2346562ce.jpg  \n",
            " extracting: train/images/youtube-89_jpg.rf.6355a0be3d2d6c4f3bc7bbd5cac27da7.jpg  \n",
            " extracting: train/images/youtube-91_jpg.rf.a58e2c190dc9cd18b906afa62d2f9782.jpg  \n",
            " extracting: train/images/youtube-91_jpg.rf.ad9cd16951bdcbed8bd1ae3e80e13ebe.jpg  \n",
            " extracting: train/images/youtube-93_jpg.rf.53315dfe1eaefb45538fc01b176a0029.jpg  \n",
            " extracting: train/images/youtube-95_jpg.rf.5b8c877af43b13bd45b41aa6afad9a15.jpg  \n",
            " extracting: train/images/youtube-96_jpg.rf.7717970f34001da8f27d759ffe560ed8.jpg  \n",
            " extracting: train/images/youtube-96_jpg.rf.d04a215b768fcc7cf7a8d75e890f5ebf.jpg  \n",
            " extracting: train/images/youtube-97_jpg.rf.d412cd7054a4e7b14cbbf5b933594742.jpg  \n",
            " extracting: train/images/youtube-99_jpg.rf.49ee2fa499ae74f7047169b720e30dfe.jpg  \n",
            " extracting: train/images/youtube-9_jpg.rf.b75c6a50ea5417b0e848a0915e288049.jpg  \n",
            "   creating: train/labels/\n",
            " extracting: train/labels/youtube-103_jpg.rf.627cfd0e3db2dcdd327ca303d268ea04.txt  \n",
            " extracting: train/labels/youtube-104_jpg.rf.39ba30657004c67e24207006e92ec7f8.txt  \n",
            " extracting: train/labels/youtube-106_jpg.rf.a654800df370fb72054ea2ab7845322e.txt  \n",
            " extracting: train/labels/youtube-107_jpg.rf.5efb0d75969553739465bbca3613b7e9.txt  \n",
            " extracting: train/labels/youtube-110_jpg.rf.f1bee775c9ac171015a033b08e133e26.txt  \n",
            " extracting: train/labels/youtube-112_jpg.rf.0a555b8105499df88467fde0701c269e.txt  \n",
            " extracting: train/labels/youtube-112_jpg.rf.ff323bb7062ba870544ae89098c03762.txt  \n",
            " extracting: train/labels/youtube-114_jpg.rf.eddddc9d068520a74adc8337b2976fd2.txt  \n",
            " extracting: train/labels/youtube-116_jpg.rf.ab16d6296bd364c408b5a10cc6a26007.txt  \n",
            " extracting: train/labels/youtube-117_jpg.rf.c2792193a6d0885f9eaa66f9d6c321a0.txt  \n",
            " extracting: train/labels/youtube-119_jpg.rf.c17b4c3736fca8743e060035e8427454.txt  \n",
            " extracting: train/labels/youtube-120_jpg.rf.6563b44f4e4bac53dfca94a205b58916.txt  \n",
            " extracting: train/labels/youtube-121_jpg.rf.1c77931b143cc706ad5d570fa75e3bdb.txt  \n",
            " extracting: train/labels/youtube-123_jpg.rf.8f9dda47c14bc19514a4aebaf553d25a.txt  \n",
            " extracting: train/labels/youtube-124_jpg.rf.5984af8dcba0df650f5cdc2bfacff380.txt  \n",
            " extracting: train/labels/youtube-124_jpg.rf.a00081154de49ba85bd73fd1218783d2.txt  \n",
            " extracting: train/labels/youtube-129_jpg.rf.d19ed916f875cc05cdc4c84d41b8fed0.txt  \n",
            " extracting: train/labels/youtube-12_jpg.rf.927c83638feb49b43ad150396f34ea41.txt  \n",
            " extracting: train/labels/youtube-130_jpg.rf.62605d4bbf5a09faa4a15ed05a4976fd.txt  \n",
            " extracting: train/labels/youtube-130_jpg.rf.ab077fb0c3af6703e083c8bf7abf7839.txt  \n",
            " extracting: train/labels/youtube-131_jpg.rf.be3ee201a2d20969c8dd1a1760128532.txt  \n",
            " extracting: train/labels/youtube-133_jpg.rf.e814fda87ead61ff013a4c52722b109c.txt  \n",
            " extracting: train/labels/youtube-137_jpg.rf.4c506ce6496379f43e06b6fbe90c6f26.txt  \n",
            " extracting: train/labels/youtube-137_jpg.rf.f202c0edfaf34a2b742c0c3894ff4944.txt  \n",
            " extracting: train/labels/youtube-138_jpg.rf.16c5b69d46b286d1ff481c46f4351216.txt  \n",
            " extracting: train/labels/youtube-140_jpg.rf.f29ff14ac179b6df877cb62d792b1074.txt  \n",
            " extracting: train/labels/youtube-141_jpg.rf.945ec3bcd999cf5ff428ec1094a1358a.txt  \n",
            " extracting: train/labels/youtube-143_jpg.rf.4ee725bec7561afe53c51ebb78b271e7.txt  \n",
            " extracting: train/labels/youtube-144_jpg.rf.0e79ef9b3d47a5b1a2499b3a9777c169.txt  \n",
            " extracting: train/labels/youtube-145_jpg.rf.1fc25d3a4e06b4983c96cb14468b46de.txt  \n",
            " extracting: train/labels/youtube-148_jpg.rf.7038db39b441a86076ff712c99781a68.txt  \n",
            " extracting: train/labels/youtube-151_jpg.rf.29ef4e86516ebb6afd852ae747aea36c.txt  \n",
            " extracting: train/labels/youtube-15_jpg.rf.dcad7a2c83a517d0debd19066d0def34.txt  \n",
            " extracting: train/labels/youtube-16_jpg.rf.060d4051e07e49d4b7554ab245945e34.txt  \n",
            " extracting: train/labels/youtube-17_jpg.rf.2b55ded179ef004b3edad03b300c879b.txt  \n",
            " extracting: train/labels/youtube-19_jpg.rf.3b30e8eebc05c3cbb735d64417d8d3f6.txt  \n",
            " extracting: train/labels/youtube-20_jpg.rf.1766333b5814ba31875b7b1dd373ccac.txt  \n",
            " extracting: train/labels/youtube-22_jpg.rf.d571de09a603f6cdd78f68f5d0a642b8.txt  \n",
            " extracting: train/labels/youtube-23_jpg.rf.b38fef22f7358d748328e71c1c0b1e35.txt  \n",
            " extracting: train/labels/youtube-24_jpg.rf.8455f8e5879475e057bf951061b475d7.txt  \n",
            " extracting: train/labels/youtube-25_jpg.rf.9c5c68a195871713fbcefeb66ea37718.txt  \n",
            " extracting: train/labels/youtube-26_jpg.rf.c8844b1f3da80f230f692912df8b2d41.txt  \n",
            " extracting: train/labels/youtube-28_jpg.rf.a794dd5de7822088e4372ec1907e0eb0.txt  \n",
            " extracting: train/labels/youtube-2_jpg.rf.560d8a73505f2d2df4f8869048561785.txt  \n",
            " extracting: train/labels/youtube-30_jpg.rf.49fce322aeabae042753410b3b2e1a33.txt  \n",
            " extracting: train/labels/youtube-31_jpg.rf.58eacdb21efb9e8074ca40e87626a594.txt  \n",
            " extracting: train/labels/youtube-35_jpg.rf.ad275f24b66b634ab7b9eb62966855a0.txt  \n",
            " extracting: train/labels/youtube-36_jpg.rf.1d418652cc78dff6deb1ccc6826b986d.txt  \n",
            " extracting: train/labels/youtube-37_jpg.rf.e6e6de59d7bb29512cdc60723d168b2b.txt  \n",
            " extracting: train/labels/youtube-39_jpg.rf.0880a55cd6c93d3b58fdcd3645f3daf2.txt  \n",
            " extracting: train/labels/youtube-40_jpg.rf.9629254ced5e1a8432aa91f682f0c157.txt  \n",
            " extracting: train/labels/youtube-41_jpg.rf.12ac341868ffca0a7d87bf14cec2e87e.txt  \n",
            " extracting: train/labels/youtube-44_jpg.rf.2b3e21f0391e0b3b971e800a4598b636.txt  \n",
            " extracting: train/labels/youtube-45_jpg.rf.1b7d98b0795536133be1c5e62622cf3a.txt  \n",
            " extracting: train/labels/youtube-48_jpg.rf.0df4d49c270df189a0f0ab4586bcd60c.txt  \n",
            " extracting: train/labels/youtube-4_jpg.rf.a7f901486b15ab7f673b1168fbbceb2e.txt  \n",
            " extracting: train/labels/youtube-50_jpg.rf.885e627443de2555682788c7554cf541.txt  \n",
            " extracting: train/labels/youtube-51_jpg.rf.074f47df3bea6217444e0601a9a494bd.txt  \n",
            " extracting: train/labels/youtube-52_jpg.rf.0bcc217e83b3176790bbac6d6797c8df.txt  \n",
            " extracting: train/labels/youtube-53_jpg.rf.d5f294fb0d7d2e5400c545be3ee5eb91.txt  \n",
            " extracting: train/labels/youtube-54_jpg.rf.fc878b8c350a6c9095b1b78c80577037.txt  \n",
            " extracting: train/labels/youtube-55_jpg.rf.050a4cae88e32ff029c75d3607ada0cc.txt  \n",
            " extracting: train/labels/youtube-56_jpg.rf.596c86f72313ea9e0e851db88f78a63a.txt  \n",
            " extracting: train/labels/youtube-58_jpg.rf.ed01d8acead8d4d094ebb2293e5e8fef.txt  \n",
            " extracting: train/labels/youtube-60_jpg.rf.e35de5f03f4f578083cb05ea69fcae5b.txt  \n",
            " extracting: train/labels/youtube-61_jpg.rf.86e5dacdf20a36d2bcb29c04dc646138.txt  \n",
            " extracting: train/labels/youtube-63_jpg.rf.43ebce342c9f30b4260dc8c999326631.txt  \n",
            " extracting: train/labels/youtube-64_jpg.rf.750942f30364efb538b71d40f302bc6f.txt  \n",
            " extracting: train/labels/youtube-66_jpg.rf.9921dba835a67d29911cdbc768225290.txt  \n",
            " extracting: train/labels/youtube-67_jpg.rf.2ff8d927a07c64f84236e35333cc831e.txt  \n",
            " extracting: train/labels/youtube-68_jpg.rf.3f571fd05de86821abda984184cf4766.txt  \n",
            " extracting: train/labels/youtube-69_jpg.rf.722f4cb1ae7216905959766f1da98f25.txt  \n",
            " extracting: train/labels/youtube-6_jpg.rf.b5da2151ad1afc589d46a277ae5b16ee.txt  \n",
            " extracting: train/labels/youtube-70_jpg.rf.1fdedbb7f7e6465413efa8538b9b683b.txt  \n",
            " extracting: train/labels/youtube-71_jpg.rf.0e4099482394b04a0a6d1f5e852e914a.txt  \n",
            " extracting: train/labels/youtube-72_jpg.rf.5239daddc140feccdb1396d5e61f5060.txt  \n",
            " extracting: train/labels/youtube-73_jpg.rf.ceb75929e75f8fdb2570e9db5c611542.txt  \n",
            " extracting: train/labels/youtube-74_jpg.rf.aea85df397b20ab30b83f30357ae16c2.txt  \n",
            " extracting: train/labels/youtube-75_jpg.rf.331f00d798839023b3239d113ba94f76.txt  \n",
            " extracting: train/labels/youtube-76_jpg.rf.f62ffa25fbf19d4c3c7eb6da6a75b126.txt  \n",
            " extracting: train/labels/youtube-77_jpg.rf.04c447c256bd1e721909147fdd884468.txt  \n",
            " extracting: train/labels/youtube-79_jpg.rf.48a637bce8980c9bc79a6399ef53cb41.txt  \n",
            " extracting: train/labels/youtube-80_jpg.rf.b4866119b9e91331d21734edb4907f71.txt  \n",
            " extracting: train/labels/youtube-82_jpg.rf.f34e75c0d9d468a93eb081b3f397bc25.txt  \n",
            " extracting: train/labels/youtube-83_jpg.rf.4ea5ea38948553093e9cfb59474c8c02.txt  \n",
            " extracting: train/labels/youtube-86_jpg.rf.f279f20a3e476e01e4636b948b17ecb2.txt  \n",
            " extracting: train/labels/youtube-88_jpg.rf.d75f37d9b7d64b838202eff2346562ce.txt  \n",
            " extracting: train/labels/youtube-89_jpg.rf.6355a0be3d2d6c4f3bc7bbd5cac27da7.txt  \n",
            " extracting: train/labels/youtube-91_jpg.rf.a58e2c190dc9cd18b906afa62d2f9782.txt  \n",
            " extracting: train/labels/youtube-91_jpg.rf.ad9cd16951bdcbed8bd1ae3e80e13ebe.txt  \n",
            " extracting: train/labels/youtube-93_jpg.rf.53315dfe1eaefb45538fc01b176a0029.txt  \n",
            " extracting: train/labels/youtube-95_jpg.rf.5b8c877af43b13bd45b41aa6afad9a15.txt  \n",
            " extracting: train/labels/youtube-96_jpg.rf.7717970f34001da8f27d759ffe560ed8.txt  \n",
            " extracting: train/labels/youtube-96_jpg.rf.d04a215b768fcc7cf7a8d75e890f5ebf.txt  \n",
            " extracting: train/labels/youtube-97_jpg.rf.d412cd7054a4e7b14cbbf5b933594742.txt  \n",
            " extracting: train/labels/youtube-99_jpg.rf.49ee2fa499ae74f7047169b720e30dfe.txt  \n",
            " extracting: train/labels/youtube-9_jpg.rf.b75c6a50ea5417b0e848a0915e288049.txt  \n",
            "   creating: valid/\n",
            "   creating: valid/images/\n",
            " extracting: valid/images/youtube-100_jpg.rf.e1dbf73f1a067dba3503421ce7cf8394.jpg  \n",
            " extracting: valid/images/youtube-106_jpg.rf.67f023a7e6bd0d2699abffe52b42d4c1.jpg  \n",
            " extracting: valid/images/youtube-108_jpg.rf.bfc27a69169b8390c19ca2bddb8c5deb.jpg  \n",
            " extracting: valid/images/youtube-10_jpg.rf.395aa36b4d04207a592d0e1f034f8d91.jpg  \n",
            " extracting: valid/images/youtube-116_jpg.rf.0b496745478c09e1e6f6cc946e9e8687.jpg  \n",
            " extracting: valid/images/youtube-126_jpg.rf.76a4af1fc24e66d4731f4ef900b72c31.jpg  \n",
            " extracting: valid/images/youtube-128_jpg.rf.b88933e6ac0142b05c902121fb6c7c88.jpg  \n",
            " extracting: valid/images/youtube-134_jpg.rf.29eb31d118b6b73935eaf2d793292520.jpg  \n",
            " extracting: valid/images/youtube-13_jpg.rf.97ba6aae2001f56d2642052799e4ea90.jpg  \n",
            " extracting: valid/images/youtube-14_jpg.rf.10f6f6e1aa307097bc36fff41a00c290.jpg  \n",
            " extracting: valid/images/youtube-16_jpg.rf.d780bbf9159bc21000ed7f556bbaf28f.jpg  \n",
            " extracting: valid/images/youtube-1_jpg.rf.2d83d213e564633c3a75ac81536476e7.jpg  \n",
            " extracting: valid/images/youtube-29_jpg.rf.23d2c16a59375710fb72cfbbf98773d4.jpg  \n",
            " extracting: valid/images/youtube-32_jpg.rf.aeb3f30314cdc8539072f9fa9f3c97cc.jpg  \n",
            " extracting: valid/images/youtube-34_jpg.rf.5ab07753bc79e2cea536de1207f46019.jpg  \n",
            " extracting: valid/images/youtube-38_jpg.rf.1fbd2ce3077b6a1c90398278807a2e88.jpg  \n",
            " extracting: valid/images/youtube-3_jpg.rf.ee16bc980ea2b7d112ddb1bc9c2d1e22.jpg  \n",
            " extracting: valid/images/youtube-42_jpg.rf.8009c376e560d4fb9855cd87c8b3f19d.jpg  \n",
            " extracting: valid/images/youtube-43_jpg.rf.f7f8a123ca8ae800529a9884a1b10c6e.jpg  \n",
            " extracting: valid/images/youtube-46_jpg.rf.b2b82874e2b260cfb7f54d88ac53e5f5.jpg  \n",
            " extracting: valid/images/youtube-49_jpg.rf.e3ffa307dfe416e43b327f50b5336a3d.jpg  \n",
            " extracting: valid/images/youtube-57_jpg.rf.f668ed6ce44ec1dde83ed97cb3bc3300.jpg  \n",
            " extracting: valid/images/youtube-59_jpg.rf.d3e9f72f090dca6b62fdfa1aed383138.jpg  \n",
            " extracting: valid/images/youtube-62_jpg.rf.9e5203b0b0db02cadeee2e0cc4ce9fdd.jpg  \n",
            " extracting: valid/images/youtube-81_jpg.rf.6d3ac0fc2986ae4942a2936995da358e.jpg  \n",
            " extracting: valid/images/youtube-85_jpg.rf.d6d8238f34069fec7a0c703990ae4aba.jpg  \n",
            " extracting: valid/images/youtube-92_jpg.rf.c3ad29a47b6dc3eef352af62c51fb08b.jpg  \n",
            "   creating: valid/labels/\n",
            " extracting: valid/labels/youtube-100_jpg.rf.e1dbf73f1a067dba3503421ce7cf8394.txt  \n",
            " extracting: valid/labels/youtube-106_jpg.rf.67f023a7e6bd0d2699abffe52b42d4c1.txt  \n",
            " extracting: valid/labels/youtube-108_jpg.rf.bfc27a69169b8390c19ca2bddb8c5deb.txt  \n",
            " extracting: valid/labels/youtube-10_jpg.rf.395aa36b4d04207a592d0e1f034f8d91.txt  \n",
            " extracting: valid/labels/youtube-116_jpg.rf.0b496745478c09e1e6f6cc946e9e8687.txt  \n",
            " extracting: valid/labels/youtube-126_jpg.rf.76a4af1fc24e66d4731f4ef900b72c31.txt  \n",
            " extracting: valid/labels/youtube-128_jpg.rf.b88933e6ac0142b05c902121fb6c7c88.txt  \n",
            " extracting: valid/labels/youtube-134_jpg.rf.29eb31d118b6b73935eaf2d793292520.txt  \n",
            " extracting: valid/labels/youtube-13_jpg.rf.97ba6aae2001f56d2642052799e4ea90.txt  \n",
            " extracting: valid/labels/youtube-14_jpg.rf.10f6f6e1aa307097bc36fff41a00c290.txt  \n",
            " extracting: valid/labels/youtube-16_jpg.rf.d780bbf9159bc21000ed7f556bbaf28f.txt  \n",
            " extracting: valid/labels/youtube-1_jpg.rf.2d83d213e564633c3a75ac81536476e7.txt  \n",
            " extracting: valid/labels/youtube-29_jpg.rf.23d2c16a59375710fb72cfbbf98773d4.txt  \n",
            " extracting: valid/labels/youtube-32_jpg.rf.aeb3f30314cdc8539072f9fa9f3c97cc.txt  \n",
            " extracting: valid/labels/youtube-34_jpg.rf.5ab07753bc79e2cea536de1207f46019.txt  \n",
            " extracting: valid/labels/youtube-38_jpg.rf.1fbd2ce3077b6a1c90398278807a2e88.txt  \n",
            " extracting: valid/labels/youtube-3_jpg.rf.ee16bc980ea2b7d112ddb1bc9c2d1e22.txt  \n",
            " extracting: valid/labels/youtube-42_jpg.rf.8009c376e560d4fb9855cd87c8b3f19d.txt  \n",
            " extracting: valid/labels/youtube-43_jpg.rf.f7f8a123ca8ae800529a9884a1b10c6e.txt  \n",
            " extracting: valid/labels/youtube-46_jpg.rf.b2b82874e2b260cfb7f54d88ac53e5f5.txt  \n",
            " extracting: valid/labels/youtube-49_jpg.rf.e3ffa307dfe416e43b327f50b5336a3d.txt  \n",
            " extracting: valid/labels/youtube-57_jpg.rf.f668ed6ce44ec1dde83ed97cb3bc3300.txt  \n",
            " extracting: valid/labels/youtube-59_jpg.rf.d3e9f72f090dca6b62fdfa1aed383138.txt  \n",
            " extracting: valid/labels/youtube-62_jpg.rf.9e5203b0b0db02cadeee2e0cc4ce9fdd.txt  \n",
            " extracting: valid/labels/youtube-81_jpg.rf.6d3ac0fc2986ae4942a2936995da358e.txt  \n",
            " extracting: valid/labels/youtube-85_jpg.rf.d6d8238f34069fec7a0c703990ae4aba.txt  \n",
            " extracting: valid/labels/youtube-92_jpg.rf.c3ad29a47b6dc3eef352af62c51fb08b.txt  \n"
          ]
        }
      ],
      "source": [
        "# TODO upload your dataset or use roboflow download code\n",
        "!curl -L https://app.roboflow.com/ds/1vs3ErCF56?key=8EuGgsiV0M > roboflow.zip\n",
        "!unzip ./roboflow.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMPrHke0ANKL"
      },
      "source": [
        "### train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cud1hVoJYMXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e34efd-9cc1-497a-ff67-686c27ea5981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.200-py3-none-any.whl (644 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/644.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.4/644.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m644.5/644.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.200\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "deXoZt6e-QE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21dc8dd3-a551-4e14-a08b-e6bafe6e6362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.23M/6.23M [00:00<00:00, 204MB/s]\n",
            "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 144MB/s]\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels... 97 images, 0 backgrounds, 0 corrupt: 100% 97/97 [00:00<00:00, 1769.57it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/valid/labels... 27 images, 0 backgrounds, 0 corrupt: 100% 27/27 [00:00<00:00, 997.47it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.64G      1.987      4.694      1.588          1        640: 100% 7/7 [00:06<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.55s/it]\n",
            "                   all         27        127     0.0044      0.459     0.0498     0.0356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.32G      1.532       3.56      1.346          3        640: 100% 7/7 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.98it/s]\n",
            "                   all         27        127      0.018      0.756      0.314      0.235\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.23G      1.455      2.309      1.189         13        640: 100% 7/7 [00:01<00:00,  4.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.04it/s]\n",
            "                   all         27        127     0.0156      0.947      0.575      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.35G       1.26      1.875      1.136          8        640: 100% 7/7 [00:01<00:00,  4.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.44it/s]\n",
            "                   all         27        127     0.0158      0.959      0.666      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.33G      1.334      1.798      1.089          7        640: 100% 7/7 [00:02<00:00,  3.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.40it/s]\n",
            "                   all         27        127      0.014      0.872      0.595      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.34G      1.405       2.52      1.143          1        640: 100% 7/7 [00:01<00:00,  4.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.36it/s]\n",
            "                   all         27        127      0.981      0.109      0.591      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.33G      1.311      1.716      1.164          2        640: 100% 7/7 [00:01<00:00,  5.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.67it/s]\n",
            "                   all         27        127      0.921      0.128      0.521      0.318\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.36G      1.226      1.453      1.079          6        640: 100% 7/7 [00:01<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.04it/s]\n",
            "                   all         27        127      0.916       0.29      0.604      0.377\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.36G      1.229      1.365       1.09          8        640: 100% 7/7 [00:01<00:00,  5.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.49it/s]\n",
            "                   all         27        127      0.858      0.609      0.794      0.568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.21G      1.171      1.372      1.084          5        640: 100% 7/7 [00:01<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.15it/s]\n",
            "                   all         27        127      0.814      0.568      0.825      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.25G      1.212      1.458       1.07          4        640: 100% 7/7 [00:01<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.99it/s]\n",
            "                   all         27        127      0.849      0.616      0.843      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.33G      1.195      1.248      1.102          7        640: 100% 7/7 [00:01<00:00,  5.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.25it/s]\n",
            "                   all         27        127      0.752      0.622      0.797      0.553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.22G       1.15      1.222      1.108          5        640: 100% 7/7 [00:01<00:00,  5.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.07it/s]\n",
            "                   all         27        127      0.798      0.524      0.811      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.35G      1.197      1.271      1.103          5        640: 100% 7/7 [00:01<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.25it/s]\n",
            "                   all         27        127       0.73      0.643      0.826      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.32G      1.154      1.333      1.086          4        640: 100% 7/7 [00:01<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.39it/s]\n",
            "                   all         27        127      0.684      0.758       0.84      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.23G      1.105      1.174      1.052          3        640: 100% 7/7 [00:01<00:00,  4.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.40it/s]\n",
            "                   all         27        127        0.8      0.724      0.861       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.33G      1.117      1.139      1.058          5        640: 100% 7/7 [00:01<00:00,  5.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.93it/s]\n",
            "                   all         27        127      0.838       0.74      0.874      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.35G      1.144      1.184      1.075         17        640: 100% 7/7 [00:01<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.28it/s]\n",
            "                   all         27        127      0.844      0.836      0.878       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.32G      1.075      1.194      1.035          3        640: 100% 7/7 [00:01<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.32it/s]\n",
            "                   all         27        127      0.791      0.828      0.872      0.606\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.36G      1.137      1.133      1.061         17        640: 100% 7/7 [00:01<00:00,  4.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.21it/s]\n",
            "                   all         27        127       0.85      0.795      0.877      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.33G      1.028       1.36      1.058          1        640: 100% 7/7 [00:01<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.12it/s]\n",
            "                   all         27        127      0.921      0.749      0.891       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.33G      1.085      1.071      1.071          5        640: 100% 7/7 [00:01<00:00,  5.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.96it/s]\n",
            "                   all         27        127      0.859       0.68      0.853      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.35G      1.166      1.255      1.119          2        640: 100% 7/7 [00:01<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.16it/s]\n",
            "                   all         27        127      0.939      0.803      0.888       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.33G      1.154     0.9596      1.069          9        640: 100% 7/7 [00:02<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.25it/s]\n",
            "                   all         27        127      0.847      0.827      0.892      0.646\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.36G       1.14      1.056      1.096          4        640: 100% 7/7 [00:01<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.15it/s]\n",
            "                   all         27        127      0.894      0.752       0.88       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.22G      1.095     0.9727      1.074          6        640: 100% 7/7 [00:01<00:00,  4.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.20it/s]\n",
            "                   all         27        127      0.947      0.753      0.848      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.34G      1.087     0.9888      1.059          4        640: 100% 7/7 [00:01<00:00,  5.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.34it/s]\n",
            "                   all         27        127      0.871      0.894      0.897      0.646\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.33G      1.073      1.036      1.018          4        640: 100% 7/7 [00:01<00:00,  5.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.03it/s]\n",
            "                   all         27        127      0.857      0.873      0.903      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.36G     0.8813      2.064     0.8741          0        640: 100% 7/7 [00:01<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.37it/s]\n",
            "                   all         27        127      0.817      0.907      0.896      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.36G      1.105     0.9588      1.065         14        640: 100% 7/7 [00:01<00:00,  5.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.14it/s]\n",
            "                   all         27        127      0.868      0.869      0.881      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.34G      1.048     0.9979      1.061          3        640: 100% 7/7 [00:01<00:00,  4.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.13it/s]\n",
            "                   all         27        127      0.884      0.843      0.909      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.23G      1.052     0.9704      1.066          6        640: 100% 7/7 [00:01<00:00,  5.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.17it/s]\n",
            "                   all         27        127      0.894      0.839      0.906      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.36G     0.9558     0.8763     0.9978          7        640: 100% 7/7 [00:01<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.25it/s]\n",
            "                   all         27        127       0.87      0.884      0.912      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.36G      1.377      1.858      1.129          1        640: 100% 7/7 [00:02<00:00,  3.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "                   all         27        127      0.942      0.843      0.917       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.35G     0.9873     0.8318      1.023          7        640: 100% 7/7 [00:01<00:00,  5.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.03it/s]\n",
            "                   all         27        127      0.905      0.865      0.914      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.23G      1.072     0.8768      1.046          9        640: 100% 7/7 [00:01<00:00,  4.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.25it/s]\n",
            "                   all         27        127      0.906      0.868      0.912      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.33G     0.9827     0.8895      1.001          7        640: 100% 7/7 [00:01<00:00,  5.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.21it/s]\n",
            "                   all         27        127      0.885      0.875      0.911      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.22G      1.087     0.9524      1.051          3        640: 100% 7/7 [00:01<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.19it/s]\n",
            "                   all         27        127      0.942      0.826      0.906      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.34G     0.9305      0.828      1.009          2        640: 100% 7/7 [00:01<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.33it/s]\n",
            "                   all         27        127      0.918      0.849      0.903      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.23G      1.008     0.8134          1         12        640: 100% 7/7 [00:01<00:00,  5.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.48it/s]\n",
            "                   all         27        127      0.907       0.84        0.9      0.671\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.47G     0.8728     0.8519     0.9966          4        640: 100% 7/7 [00:04<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.01it/s]\n",
            "                   all         27        127      0.935      0.828      0.899      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.33G      1.008     0.8135      1.052          2        640: 100% 7/7 [00:01<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.14it/s]\n",
            "                   all         27        127      0.905      0.848      0.895      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.32G     0.9116     0.7627     0.9949          8        640: 100% 7/7 [00:02<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.45it/s]\n",
            "                   all         27        127      0.929      0.826      0.899      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.33G     0.9656     0.7488      1.014          4        640: 100% 7/7 [00:01<00:00,  4.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.72it/s]\n",
            "                   all         27        127      0.917      0.865      0.901      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.33G     0.8905     0.7559     0.9672          4        640: 100% 7/7 [00:01<00:00,  5.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.02it/s]\n",
            "                   all         27        127      0.881      0.875      0.903      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.33G     0.9158     0.7112     0.9727          4        640: 100% 7/7 [00:01<00:00,  5.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.79it/s]\n",
            "                   all         27        127      0.942      0.849      0.907       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.32G      0.897     0.7115     0.9746          6        640: 100% 7/7 [00:01<00:00,  5.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.53it/s]\n",
            "                   all         27        127      0.941      0.851       0.91      0.693\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.35G     0.9029     0.7568     0.9832          8        640: 100% 7/7 [00:01<00:00,  3.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.17it/s]\n",
            "                   all         27        127      0.939      0.842      0.913      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.33G     0.8757      0.739      0.971          6        640: 100% 7/7 [00:01<00:00,  5.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.32it/s]\n",
            "                   all         27        127       0.89      0.887      0.916      0.704\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.33G     0.9002     0.7143     0.9831          7        640: 100% 7/7 [00:01<00:00,  5.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.16it/s]\n",
            "                   all         27        127      0.942      0.846      0.916      0.706\n",
            "\n",
            "50 epochs completed in 0.041 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.61it/s]\n",
            "                   all         27        127      0.942      0.846      0.915      0.707\n",
            "                   bus         27         17      0.996          1      0.995       0.91\n",
            "                   car         27         84       0.91      0.846      0.942      0.652\n",
            "                 truck         27         26      0.921      0.692      0.809       0.56\n",
            "Speed: 0.2ms preprocess, 2.1ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "# TODO train the model with your dataset\n",
        "# recommend at least train 50 epochs\n",
        "!yolo detect train data=/content/data.yaml model=yolov8n.pt epochs=50 imgsz=640"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGsraJRgdSwM"
      },
      "source": [
        "#### test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kS7Yk3bxdT2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64cb730-eb69-423a-a6e1-59e1029547e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/valid/images/youtube-13_jpg.rf.97ba6aae2001f56d2642052799e4ea90.jpg: 640x640 7 cars, 1 truck, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'bus', 1: 'car', 2: 'truck'}\n",
              " orig_img: array([[[143, 146, 137],\n",
              "         [144, 145, 136],\n",
              "         [156, 154, 146],\n",
              "         ...,\n",
              "         [133, 143, 143],\n",
              "         [178, 188, 188],\n",
              "         [175, 187, 187]],\n",
              " \n",
              "        [[146, 149, 140],\n",
              "         [147, 148, 139],\n",
              "         [151, 149, 141],\n",
              "         ...,\n",
              "         [134, 144, 144],\n",
              "         [185, 195, 195],\n",
              "         [185, 197, 197]],\n",
              " \n",
              "        [[148, 151, 142],\n",
              "         [153, 154, 145],\n",
              "         [147, 145, 137],\n",
              "         ...,\n",
              "         [133, 143, 143],\n",
              "         [188, 198, 198],\n",
              "         [190, 202, 202]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 88,  71,  74],\n",
              "         [ 98,  81,  84],\n",
              "         [108,  91,  94],\n",
              "         ...,\n",
              "         [101,  94,  97],\n",
              "         [101,  94,  97],\n",
              "         [101,  94,  97]],\n",
              " \n",
              "        [[ 83,  66,  69],\n",
              "         [ 96,  79,  82],\n",
              "         [107,  90,  93],\n",
              "         ...,\n",
              "         [101,  94,  97],\n",
              "         [101,  94,  97],\n",
              "         [101,  94,  97]],\n",
              " \n",
              "        [[ 80,  63,  66],\n",
              "         [ 94,  77,  80],\n",
              "         [106,  89,  92],\n",
              "         ...,\n",
              "         [101,  94,  97],\n",
              "         [101,  94,  97],\n",
              "         [101,  94,  97]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/valid/images/youtube-13_jpg.rf.97ba6aae2001f56d2642052799e4ea90.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict'\n",
              " speed: {'preprocess': 2.131223678588867, 'inference': 9.890079498291016, 'postprocess': 3.7980079650878906}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "# TODO test your model with test img in dataset\n",
        "model = YOLO(\"/content/runs/detect/train/weights/best.pt\")\n",
        "model.predict(\"/content/valid/images/youtube-13_jpg.rf.97ba6aae2001f56d2642052799e4ea90.jpg\", save=True, imgsz=640, conf=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orpE2xr2aRNm"
      },
      "source": [
        "## export yolov8 to trt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "myLH8_0ND6GR"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "# TODO your train dir ex. runs/detect/train/\n",
        "train_path = Path(\"/content/runs/detect/train\")\n",
        "model_path = train_path / \"weights\"\n",
        "pt_file = str(model_path / \"best.pt\")\n",
        "onnx_file = str(model_path / \"best.onnx\")\n",
        "trt_file = str(model_path / \"best.engine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Jx8sSRFgYpCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f38698-dbff-4c86-a5a7-e2e4f69ba1df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.00GHz)\n",
            "Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/detect/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (6.0 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 14.6/14.6 MB 245.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (4.5.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.14.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 8.0s, installed 1 package: ['onnx>=1.12.0']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 8.7s, saved as '/content/runs/detect/train/weights/best.onnx' (11.7 MB)\n",
            "\n",
            "Export complete (10.8s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/runs/detect/train/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/runs/detect/train/weights/best.onnx imgsz=640 data=/content/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n"
          ]
        }
      ],
      "source": [
        "# tensorRT engine\n",
        "!yolo export model={pt_file} format=onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uhrzUqWq9JrW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f4d2165d-9ad1-4b42-8a83-d4d2ab8fd834"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f3a0e0e5-e32f-4bc3-9282-a3d93a9f149e\", \"best.onnx\", 12239697)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# download onnx\n",
        "from google.colab import files\n",
        "files.download(onnx_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}